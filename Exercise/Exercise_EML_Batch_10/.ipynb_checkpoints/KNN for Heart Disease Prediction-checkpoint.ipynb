{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction\n",
    "\n",
    "Data aslinya berasal dari UCI Machine Learning Repository<br>\n",
    "Silahkan cek disini https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "Berikut adalah nama-nama pihak yang menyiapkan dataset ini\n",
    "1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D. \n",
    "2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D. \n",
    "3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D. \n",
    "4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.\n",
    "\n",
    "Donor: David W. Aha (aha '@' ics.uci.edu) (714) 856-8779"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Import Numpy dan Pandas\n",
    "Silahkan import package numpy dan pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import here\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Import Data\n",
    "Berdasarkan keterangan di UCI, \n",
    "```\n",
    "This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The \"goal\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.\n",
    "```\n",
    "\n",
    "Data yang akan kita pakai adalah data penyakit jantung dari Cleveland Database.<br>\n",
    "Kita akan pakai data yang sudah diproses (hanya 14 fitur yang digunakan) sesuai keterangannya.<br>\n",
    "Silahkan import datanya menggunakan pandas -> `data/preprocessed.cleveland.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data here\n",
    "df_hd = pd.read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Replace ? dengan NaN\n",
    "\n",
    "<img src=\"assets/missing_value.png\" width=600>\n",
    "\n",
    "Kalau kita lihat datanya, ternyata missing value diisi menggunakan `?`. Padahal kita biasa menghandle missing value dalam bentuk `NaN`. Jadi kita timpa saja semua yang `?` dengan `NaN` dari numpy -> `np.nan`.\n",
    "\n",
    "Silahkan pakai `.replace()` dari pandas DataFrame untuk melakukan itu. Jangan lupa di `inplace` ya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Drop column\n",
    "Silahkan menggunakan intuisi masing-masing mana kolom yang dirasa tidak masuk akal untuk memprediksi penyakit jantung. Walau itu sudah dilakukan oleh peneliti sebelumnya (dari 76 kolom tinggal 14), tapi kita boleh saja memiliki intuisi pribadi bahwa dari 14 itu pun tidak semua dibutuhkan. Kita juga bisa melakukan `plot_missing_value` untuk cek apakah ada fitur yang terlalu banyak bolongnya karena fitur itu sebaiknya tidak dipakai.\n",
    "\n",
    "Berikut nomenklatur yang saya peroleh dari datanya:\n",
    "```\n",
    "age: Umur\n",
    "sex: jenis kelamin\n",
    "cp: chest pain. Ada 4 tipe\n",
    "    1: typical angina\n",
    "    2: atypical angina\n",
    "    3: non-anginal pain\n",
    "    4: asymptomatic\n",
    "trestbps: Tekanan darah (kondisi resting) [mmHg]\n",
    "chol: serum cholestoral [mg/dl]\n",
    "fbs: kadar gula (kondisi berpuasa)\n",
    "    1 artinya > 120 mg/dl\n",
    "    0 sebaliknya\n",
    "restecg: electrocardiographic (kondisi resting)\n",
    "    0: normal\n",
    "    1: ada ST-T wave abnormality\n",
    "    2: ada indikasi left ventricular hypertrophy menurut kriteria Estes\n",
    "thalach: detak jantung maximum\n",
    "exang: mengalami chest pain tipe angina ketika olahraga\n",
    "    1 artinya iya\n",
    "    0 artinya tidak\n",
    "oldpeak: mengalami ST depression ketika olahraga dibandingkan saat diam\n",
    "slope: kemiringan pada peak exercise ST segment -> (coba search ST Segment di google)\n",
    "    1: naik\n",
    "    2: datar\n",
    "    3: turun\n",
    "ca: banyaknya saluran saluran darah utama (0-3) dilihat dengan flourosopy\n",
    "thal: \n",
    "    3 = normal\n",
    "    6 = cacat permanen\n",
    "    7 = cacat reversibel\n",
    "target:\n",
    "    0 tidak ada indikasi penyakit jantung\n",
    "    1,2,3,4: ada indikasi penyakit jantung\n",
    "```\n",
    "Note: Translasi saya bisa saja salah karena saya juga tidak terlalu paham dengan istilah kedokteran. Jadi boleh cek langsung informasi aslinya di `data/heart-disease.names`\n",
    "\n",
    "Ok, silahkan analisa setiap fiturnya dan lakukan `plot_missing_value`. `plot_missing_value` adalah sebuah tools yang disediakan di dalam `jcopml.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Mengubah target\n",
    "\n",
    "Berdasarkan keterangan di UCI, \n",
    "```\n",
    "Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0)\n",
    "```\n",
    "kita hanya ingin mendeteksi apakah ada indikasi penyakit jantung atau tidak. Jadi:\n",
    "- 0 -> `False` (tidak ada indikasi)\n",
    "- 1, 2, 3, 4 -> `True` (ada indikasi)\n",
    "\n",
    "Hint, boleh coba pakai `.apply()` atau `.map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubah target menjadi biner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Dataset Splitting\n",
    "\n",
    "Split data menggunakan `train_test_split` dari `sklearn.model_selection`.\n",
    "Pastikan:\n",
    "- memakai stratified shuffle split<br>\n",
    "ya karena ini klasifikasi. Kita mau soal ujiannya serepresentatif mungkin.\n",
    "- test size yang sesuai<br>\n",
    "Hati-hati, pastikan soal ujian tidak terlalu sedikit agar nilainya pun tidak sensitif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Persiapkan preprocessor\n",
    "\n",
    "Steps:\n",
    "- siapkan numerical dan categorical pipeline\n",
    "- gabungkan keduanya menjadi preprocessor menggunakan ColumnTransformer\n",
    "- pilah kolom yang sesuai untuk numerical dan categorical pipeline\n",
    "- **Hati-hati, yang angka bukan berarti numerik, tapi bisa kategorikal juga**\n",
    "\n",
    "Jangan ragu untuk lihat kembali notebook sebelumnya ya (`4 - KNN & Scikit-learn`/`Part 3 - Scikit-learn Pipeline and Workflow`)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-73020798007e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_pipeline, categorical_pipeline, dan preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Buat Training pipeline\n",
    "\n",
    "training pipeline = preprocessor + algo dibungkus pakai pipeline. Gampang kan ya?<br>\n",
    "Untuk sekarang algonya tetap KNN ya. <br>\n",
    "Haiyo, `KNeighborsClassifier` atau `KNeighborsRegressor` nih? Jangan ketukar ya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algo here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Training, Cross Validate, Tuning, dan Evaluasi\n",
    "\n",
    "Pakai saja `GridSearchCV` dari `sklearn.model_selection`. Jangan lupa buat parameter grid nya beserta tentukan mau berapa fold CV nya.\n",
    "\n",
    "Silahkan pakai ini untuk evaluasi\n",
    "```python\n",
    "print(model.best_params_)\n",
    "print(model.score(X_train, y_train), model.best_score_, model.score(X_test, y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid, training, tuning, dan evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Save Model\n",
    "\n",
    "Bisa pickle sendiri secara manual (cek materi bonus) atau pakai `save_model` yang disediakan di `jcopml.utils`<br>\n",
    "Save model kita dengan nama `knn_heart.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Task\n",
    "\n",
    "Coba review kembali pertanyaan-pertanyaan berikut\n",
    "- Kenapa kita perlu dataset splitting?\n",
    "- Apa tujuan kita melakukan stratified shuffle split untuk klasifikasi?\n",
    "- Kenapa kita perlu kita menggunakan k-fold cross validation?\n",
    "- Apa itu Data Leakage? Kapan biasanya orang kelupaan dan terjadi leakage?\n",
    "- Apa itu Train-Val-Test split?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jcopml]",
   "language": "python",
   "name": "conda-env-jcopml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
